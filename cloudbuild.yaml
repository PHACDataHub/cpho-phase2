# To trigger manually, use `gcloud builds submit --config cloudbuild.yaml`
# Note: manual triggers differ from GitHub triggers on the available built in substitution values
# deploy/make_cloud_build_env_file.sh is responsible for providing local fallbacks as needed


# [START cloudrun_django_cloudbuild]
steps:
  - id: "Make .env.cloud_build for subsequent steps"
    name: gcr.io/cloud-builders/gcloud
    env:
      - "BRANCH_NAME=${BRANCH_NAME}"
      - "COMMIT_SHA=${COMMIT_SHA}"
    script: |
      #!/usr/bin/env bash
      set -o errexit
      set -o pipefail
      set -o nounset

      echo "Write .env.cloud_build to disk, to provide consistent project configuration (no secrets) in subsequent steps"
      deploy/make_cloud_build_env_file.sh "${BRANCH_NAME}" "${COMMIT_SHA}"

  - id: "Run tests"
    name: "gcr.io/cloud-builders/docker"
    script: |
      #!/usr/bin/env bash
      set -o errexit
      set -o pipefail
      set -o nounset
      
      echo "Get cloud build project configuration values"
      source .env.cloud_build

      echo "Build images for testing, run tests and create report"
      # TODO: Upload coverage report to somewhere like Google Cloud Storage, and determine how to more easily access results - currently we need to dig through the Cloud Build logs in order to view the report.  
      # docker compose -f docker-compose.run-tests.yaml build --no-cache
      docker compose -f docker-compose.run-tests.yaml up --exit-code-from server
      # NOTE: Tests are run within docker compose. When "--exit-code-from" is used, and the build or a command fails, this flag will cause the step to fail.
      
      echo "Copy test coverage report from docker compose volume to Google Gloud Storage."
      cp ./coverage/coverage.json gs://hopic-test-coverage-reports/deployment_test_coverage_report
      
      echo "Tear down containers and volumes"
      docker compose -f docker-compose.run-tests.yaml down -v

  # - id: "Upload test coverage reports to Google Cloud Storage"
  #   name: 'gcr.io/cloud-builders/gsutil'
  #   script: |
  #     #!/usr/bin/env bash
  #     set -o errexit
  #     set -o pipefail
  #     set -o nounset
      
  #     echo "Get cloud build project configuration values"
  #     source .env.cloud_build

  #     echo "pwd is ${PWD}"
  #     cbfilenames=`ls ./coverage`
  #     for eachfile in $cbfilenames
  #     do
  #       echo $eachfile
  #     done

  #     echo "Copy test coverage report from docker compose volume to Google Gloud Storage."
  #     # echo "deployment_test_coverage_report:$BRANCH:$COMMIT_SHA:$(date +%s)""
  #     cp .coverage/coverage.json gs://hopic-test-coverage-reports/deployment_test_coverage_report
  #     #:$BRANCH:$COMMIT_SHA:$(date +%s)

  - id: "Build image if main"
    name: "gcr.io/cloud-builders/docker"
    script: |
      #!/usr/bin/env bash
      set -o errexit
      set -o pipefail
      set -o nounset
      
      echo "Get cloud build environment variables"
      source .env.cloud_build

      if [[ "${BRANCH_NAME}" == "${GITHUB_MAIN_BRANCH_NAME}" ]]; then
        echo "Build a new application run time image"
        docker build -t "${IMAGE_NAME_FOR_RUN}" -f ./server/Dockerfile ./server
       else
        echo "pass"
      fi

  - id: "Push image if main"
    name: "gcr.io/cloud-builders/docker"
    script: |
      #!/usr/bin/env bash
      set -o errexit
      set -o pipefail
      set -o nounset
      
      echo "Get cloud build environment variables"
      source .env.cloud_build

      if [[ "${BRANCH_NAME}" == "${GITHUB_MAIN_BRANCH_NAME}" ]]; then
        echo "Push the new image to the project's artifact registry"
        docker push "${IMAGE_NAME_FOR_RUN}"
      else
        echo "pass"
        exit 0
      fi

  - id: "Deploy to Cloud Run if main"
    name: "gcr.io/cloud-builders/gcloud"
    script: |
      #!/usr/bin/env bash
      set -o errexit
      set -o pipefail
      set -o nounset
      
      echo "Get cloud build environment variables"
      source .env.cloud_build

      # IMPORTANT: don't just use latest. The secrets are mounted at container start, not deploy time,
      # so instances deployed with "latest" may end up using incompatable secret versions as new secret
      # versions are pushed, but before the coresponding images are pushed
      prod_env_secret_version=6

      if [[ "${BRANCH_NAME}" == "${GITHUB_MAIN_BRANCH_NAME}" ]]; then
        echo "Deploy new image to Cloud Run"
        gcloud run deploy "${PROJECT_SERVICE_NAME}" \
          --image "${IMAGE_NAME_FOR_RUN}" \
          --region "${PROJECT_REGION}" \
          --add-cloudsql-instances "${DB_INSTANCE_NAME}" \
          --vpc-connector "${VPC_CONNECTOR_NAME}" \
          --set-secrets "/secrets/.env.prod=${SKEY_PROD_ENV_FILE}:${prod_env_secret_version}" \
          --platform managed \
          --allow-unauthenticated
      else
        echo "pass"
        exit 0
      fi
# [END cloudrun_django_cloudbuild]
